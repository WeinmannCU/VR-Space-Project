// Copyright (c) Meta Platforms, Inc. and affiliates.

// @generated by `buck2 run //arvr/projects/mixedreality/libraries/mrutilitykit:build_and_deploy unreal`

#pragma once

#include <float.h>
#include <stddef.h>
#include <stdint.h>
#include "CoreTypes.h"
#include "Math/UnrealMath.h"
#include "Math/MathFwd.h"

struct MRUKShared
{
    static MRUKShared* GetInstance() { return Instance; }

    static void LoadMRUKSharedLibrary();
    static void FreeMRUKSharedLibrary();

    struct SceneAnchor;

    struct RoomAnchor;

    struct Trackable;

    struct Uuid;

    struct Posef;

    enum class RendererType
    {
        None = 0,
        Vulkan = 1,
        Opengl = 2,
    };

    enum class SceneModel
    {
        V2FallbackV1 = 0,
        V1 = 1,
        V2 = 2,
    };

    enum class LogLevel
    {
        Debug = 0,
        Info = 1,
        Warn = 2,
        Error = 3,
    };

    enum class Result
    {
        Success = 0,
        ErrorInvalidArgs = 1,
        ErrorUnknown = 2,
        ErrorInternal = 3,
        ErrorDiscoveryOngoing = 4,
        ErrorInvalidJson = 5,
        ErrorNoRoomsFound = 6,
        ErrorInsufficientResources = 7,
        ErrorStorageAtCapacity = 8,
        ErrorInsufficientView = 9,
        ErrorPermissionInsufficient = 10,
        ErrorRateLimited = 11,
        ErrorTooDark = 12,
        ErrorTooBright = 13,
        ErrorNotReady = 14,
        ErrorUnsupported = 15,
    };

    enum class SurfaceType
    {
        None = 0,
        Plane = 1,
        Volume = 2,
        Mesh = 4,
        All = 7,
    };

    enum class Label
    {
        Floor = 1,
        Ceiling = 2,
        WallFace = 4,
        Table = 8,
        Couch = 16,
        DoorFrame = 32,
        WindowFrame = 64,
        Other = 128,
        Storage = 256,
        Bed = 512,
        Screen = 1024,
        Lamp = 2048,
        Plant = 4096,
        WallArt = 8192,
        SceneMesh = 16384,
        InvisibleWallFace = 32768,
        Unknown = 131072,
        InnerWallFace = 262144,
        Tabletop = 524288,
        SittingArea = 1048576,
        SleepingArea = 2097152,
        StorageTop = 4194304,
    };

    enum class TrackableType
    {
        None = 0,
        Keyboard = 1,
        Qrcode = 2,
    };

    enum class MarkerPayloadType
    {
        None = 0,
        InvalidQrcode = 1,
        StringQrcode = 2,
        BinaryQrcode = 3,
    };

    enum class EnvironmentRaycastStatus
    {
        Hit = 1,
        NoHit = 2,
        HitPointOccluded = 3,
        HitPointOutsideFov = 4,
        RayOccluded = 5,
        InvalidOrientation = 6,
        Max = 2147483647,
    };

    enum class EnvironmentRaycasterStatus
    {
        Stopped = 0,
        Creating = 1,
        Ready = 2,
    };

    typedef void (*LogPrinter)(LogLevel logLevel, const char* message, uint32_t length);

    typedef void (*OnPreRoomAnchorAdded)(const RoomAnchor* roomAnchor, void* userContext);

    typedef void (*OnRoomAnchorAdded)(const RoomAnchor* roomAnchor, void* userContext);

    typedef void (*OnRoomAnchorUpdated)(const RoomAnchor* roomAnchor, const Uuid* oldRoomAnchorUuid, bool significantChange, void* userContext);

    typedef void (*OnRoomAnchorRemoved)(const RoomAnchor* roomAnchor, void* userContext);

    typedef void (*OnSceneAnchorAdded)(const SceneAnchor* sceneAnchor, void* userContext);

    typedef void (*OnSceneAnchorUpdated)(const SceneAnchor* sceneAnchor, bool significantChange, void* userContext);

    typedef void (*OnSceneAnchorRemoved)(const SceneAnchor* sceneAnchor, void* userContext);

    typedef void (*OnDiscoveryFinished)(Result result, void* userContext);

    typedef void (*OnTrackersConfigured)(Result result, void* userContext);

    typedef void (*OnTrackableAdded)(const Trackable* trackable, void* userContext);

    typedef void (*OnTrackableUpdated)(const Trackable* trackable, void* userContext);

    typedef void (*OnTrackableRemoved)(const Trackable* trackable, void* userContext);

    typedef Posef (*TrackingSpacePoseGetter)();

    typedef void (*TrackingSpacePoseSetter)(Posef pose);

    struct LabelFilter
    {
        uint32_t surfaceType;
        uint32_t includedLabels;
        bool includedLabelsSet;
    };

    struct Quatf
    {
        float x;
        float y;
        float z;
        float w;
    };

    struct Posef
    {
        FVector3f position;
        Quatf rotation;
    };

    struct Polygon2f
    {
        const FVector2f* points;
        uint32_t numPoints;
    };

    struct Mesh2f
    {
        FVector2f* vertices;
        uint32_t numVertices;
        uint32_t* indices;
        uint32_t numIndices;
    };

    struct Mesh3f
    {
        FVector3f* vertices;
        uint32_t numVertices;
        uint32_t* indices;
        uint32_t numIndices;
    };

    struct Uuid
    {
        uint8_t data[16];
    };

    struct Volume
    {
        FVector3f min;
        FVector3f max;
    };

    struct Plane
    {
        float x;
        float y;
        float width;
        float height;
    };

    struct SceneAnchor
    {
        uint64_t space;
        Uuid uuid;
        Uuid roomUuid;
        Uuid parentUuid;
        Posef pose;
        Volume volume;
        Plane plane;
        Label semanticLabel;
        const FVector2f* planeBoundary;
        const uint32_t* globalMeshIndices;
        const FVector3f* globalMeshPositions;
        uint32_t planeBoundaryCount;
        uint32_t globalMeshIndicesCount;
        uint32_t globalMeshPositionsCount;
        bool hasVolume;
        bool hasPlane;
    };

    struct RoomFace
    {
        Uuid uuid;
        Uuid parentUuid;
        Label semanticLabel;
        const uint32_t* indices;
        uint32_t indicesCount;
    };

    struct RoomMesh
    {
        const FVector3f* vertices;
        RoomFace* faces;
        uint32_t verticesCount;
        uint32_t facesCount;
    };

    struct RoomAnchor
    {
        SceneModel sceneModel;
        uint64_t space;
        Uuid uuid;
        Posef pose;
        RoomMesh roomMesh;
    };

    struct Trackable
    {
        TrackableType trackableType;
        MarkerPayloadType markerPayloadType;
        uint64_t space;
        uint64_t entityId;
        Uuid uuid;
        Posef pose;
        Volume volume;
        Plane plane;
        const FVector2f* planeBoundary;
        const uint8_t* payload;
        uint32_t planeBoundaryCount;
        uint32_t payloadCount;
        bool hasVolume;
        bool hasPlane;
        bool isTracked;
    };

    struct EventListener
    {
        OnPreRoomAnchorAdded onPreRoomAnchorAdded;
        OnRoomAnchorAdded onRoomAnchorAdded;
        OnRoomAnchorUpdated onRoomAnchorUpdated;
        OnRoomAnchorRemoved onRoomAnchorRemoved;
        OnSceneAnchorAdded onSceneAnchorAdded;
        OnSceneAnchorUpdated onSceneAnchorUpdated;
        OnSceneAnchorRemoved onSceneAnchorRemoved;
        OnDiscoveryFinished onDiscoveryFinished;
        OnTrackersConfigured onTrackersConfigured;
        OnTrackableAdded onTrackableAdded;
        OnTrackableUpdated onTrackableUpdated;
        OnTrackableRemoved onTrackableRemoved;
        void* userContext;
    };

    struct Hit
    {
        Uuid roomAnchorUuid;
        Uuid sceneAnchorUuid;
        float hitDistance;
        FVector3f hitPosition;
        FVector3f hitNormal;
    };

    struct SharedRoomsData
    {
        Uuid groupUuid;
        Uuid* roomUuids;
        uint32_t numRoomUuids;
        Uuid alignmentRoomUuid;
        Posef roomWorldPoseOnHost;
    };

    struct _MrukUuidAlignmentTest
    {
        uint8_t padding;
        Uuid uuid;
    };

    struct EnvironmentRaycastHitPointGetInfo
    {
        FVector3f startPoint;
        FVector3f direction;
        uint32_t filterCount;
        float maxDistance;
    };

    struct EnvironmentRaycastHitPoint
    {
        EnvironmentRaycastStatus status;
        FVector3f point;
        Quatf orientation;
        FVector3f normal;
    };

    struct Vector2i
    {
        int x;
        int y;
    };

    struct CameraIntrinsics
    {
        FVector2f focalLength;
        FVector2f principalPoint;
        FVector3f lensTranslation;
        Quatf lensRotation;
        Vector2i sensorResolution;
    };

    struct Config
    {
        const char* appDataPath;
        bool flipPcaTextureVertically;
        bool isLinearColorSpace;
    };


    /// This allows the engine to intercept the logs from the shared library and print them using the
    /// engine's logging system. Note that the log lines are NOT NULL terminated, and so you must take
    /// into account the length and be careful not to read past it.
    void (*SetLogPrinter)(LogPrinter printer);

    /// This should only be called once on application startup to create the global context. This is a
    /// pre-requisite to call all of the other APIs. When the context is not needed anymore it should be
    /// destroyed with ContextDestroy() to free resources (i.e. when the application is shutdown).
    Result (*CreateGlobalContext)(const Config* config);

    /// Destroy the global context
    /// This should only be called once on application shutdown.
    void (*DestroyGlobalContext)();

    /// Initialize OpenXR with an external OpenXR instance and session.
    /// This should only be called once on application startup.
    /// Make sure to hook up the OnOpenXrEvent() function as well.
    /// If the context is not needed anymore it should be destroyed with ContextDestroy() to free
    /// resources.
    Result (*InitOpenXr)(uint64_t xrInstance, uint64_t xrSession, void* xrInstanceProcAddrFunc, uint64_t baseSpace, const char** availableOpenXrExtensions, uint32_t availableOpenXrExtensionsCount);

    /// This should be called when the OpenXR instance is destroyed and it is no longer valid to attempt
    /// to make any OpenXR calls. This can happen with Link when exiting play mode.
    void (*ShutdownOpenXr)();

    /// Initialize the Unity interfaces. This should be called once after the global context has been
    /// created. See https://docs.unity3d.com/6000.1/Documentation/Manual/native-plugin-interface.html
    /// for more details. Note that the usual UnityPluginLoad and UnityPluginUnload functions will not
    /// be called automatically by unity because the MRUK Shared Library is loaded dynamically at
    /// runtime to allow hot reloading. So we must explicitly call this ourselves to get access to the
    /// interface.
    ///
    /// @param[in] unityInterfaces A pointer to IUnityInterfaces
    void (*InitGraphicsFromUnity)(void* unityInterfaces);

    /// Initialize the graphics. This should be called once after the global context has been created.
    /// @param[in] rendererType Which renderer to use.
    void (*InitGraphics)(RendererType rendererType);

    /// If the base space changes after initialization, this function should be called to update the
    /// base space.
    void (*SetBaseSpace)(uint64_t baseSpace);

    /// Start anchor discovery in the global context
    Result (*StartDiscovery)(bool shouldRemoveMissingRooms, SceneModel sceneModel);

    /// Start anchor query from shared group uuid in the global context
    Result (*StartQueryByLocalGroup)(SharedRoomsData sharedRoomsData, bool shouldRemoveMissingRooms, SceneModel sceneModel);

    /// Load the scene from a json string
    Result (*LoadSceneFromJson)(const char* jsonString, bool shouldRemoveMissingRooms, SceneModel sceneModel);

    /// Save the scene to a json string.
    /// @return The serialized JSON string. This string must be freed with FreeJson after use!
    const char* (*SaveSceneToJson)(bool includeGlobalMesh, Uuid* roomUuids, uint32_t numRoomUuids);

    /// Free the json string returned by SaveSceneToJson.
    /// @param[in] jsonString The JSON string to free.
    void (*FreeJson)(const char* jsonString);

    /// Given a prefabricated scene description, load it in the global context.
    Result (*LoadSceneFromPrefab)(RoomAnchor* roomAnchors, uint32_t numRoomAnchors, SceneAnchor* sceneAnchors, uint32_t numSceneAnchors);

    /// Clear and remove all rooms in the global context.
    void (*ClearRooms)();

    /// Clear and remove the room that matches the given uuid.
    void (*ClearRoom)(Uuid roomUuid);

    /// Allows to forward OpenXR events from the engine into the shared library
    void (*OnOpenXrEvent)(void* baseEventHeader);

    /// Needs to be called every tick by the engine.
    void (*TickGlobalContext)(uint64_t nextPredictedDisplayTime);
    void (*RegisterEventListener)(EventListener listener);

    /// Cast a ray against all anchors in the room and return the first hit.
    /// A maxDistance of <= 0 will return the first hit regardless of distance.
    bool (*RaycastRoom)(Uuid roomUuid, FVector3f origin, FVector3f direction, float maxDistance, LabelFilter labelFilter, Hit* outHit);

    /// Cast a ray against all anchors in the room and return all hits along the ray.
    /// A maxDistance of <= 0 will return the hits along the ray regardless of distance.
    bool (*RaycastRoomAll)(Uuid roomUuid, FVector3f origin, FVector3f direction, float maxDistance, LabelFilter labelFilter, Hit* outHits, uint32_t* outHitsCount);

    /// Cast a ray against the anchor in the room and return the first hit.
    /// A maxDistance of <= 0 will return the hits along the ray regardless of distance.
    bool (*RaycastAnchor)(Uuid sceneAnchorUuid, FVector3f origin, FVector3f direction, float maxDistance, uint32_t surfaceTypes, Hit* outHit);

    /// Cast a ray against the anchor in the room and return all hits along the ray.
    /// A maxDistance of <= 0 will return the hits along the ray regardless of distance.
    bool (*RaycastAnchorAll)(Uuid sceneAnchorUuid, FVector3f origin, FVector3f direction, float maxDistance, uint32_t surfaceTypes, Hit* outHits, uint32_t* outHitsCount);

    /// Check if the given position is in the room or not.
    ///
    /// @param[in] roomUuid The unique identifier for the room.
    /// @param[in] position The 3D position to check.
    /// @param[in] testVerticalBounds A boolean indicating whether to test vertical bounds. If false
    /// then the point will be considered inside as long as it is within the perimeter of the room
    /// regardless of whether the point is below the floor or above the ceiling.
    /// @return True if the position is within the room, false otherwise.
    bool (*IsPositionInRoom)(Uuid roomUuid, FVector3f position, bool testVerticalBounds);

    /// Gets the current room the headset is in. If the headset is not in any given room
    /// then it will return the room the headset was last in when this function was called.
    /// If the headset hasn't been in a valid room yet then return the first room in the list.
    /// If no rooms have been loaded yet then return false.
    ///
    /// @param[out] outRoomUuid Pointer to a MrukUuid that will be filled with the current room UUID.
    /// @return True if a room was found, false otherwise.
    bool (*GetCurrentRoom)(Uuid* outRoomUuid);

    /// Checks whether scene anchor discovery is currently in progress.
    ///
    /// @return True if discovery is ongoing (either actively loading scene data or
    /// performing background processing like BVH building), false if discovery
    /// hasn't started yet or has completely finished.
    bool (*IsDiscoveryRunning)();

    /// Set a custom world lock anchor. This is used to lock the world space to a specific anchor.
    /// @param[in] anchorHandle The anchor handle to lock the world space to. If set to 0 then the world
    /// lock anchor falls back to the default world lock anchor.
    /// @param[in] initialPose The initial pose of the world lock anchor.
    bool (*SetCustomWorldLockAnchor)(uint64_t anchorHandle, Posef initialPose);

    /// Erase the persisted spatial world locking anchor. This should really only be called for
    /// debugging purposes, internally.
    bool (*ErasePersistedWorldLockAnchor)();

    /// Get the world lock offset for the current room. This is the difference between the room's
    /// initial pose when it was created and the current pose.
    bool (*GetWorldLockOffset)(Posef* offset);

    /// Add two vectors together. This is implemented as a test to ensure the native shared
    /// library is working correctly.
    ///
    /// @param[in] a The first vector.
    /// @param[in] b The second vector.
    /// @return The sum of the two vectors.
    FVector3f (*AddVectors)(FVector3f a, FVector3f b);

    /// Triangulate a polygon with holes, any winding order works. The first polyline defines the main
    /// polygon. Following polylines define holes. This function will allocate memory for the vertices
    /// and indices. You *MUST* call FreeMesh() when you are done with it or you will leak memory.
    ///
    /// @param[in] polygons The polygon to triangulate.
    /// @param[in] numPolygons The number of polygons in the array.
    /// @return mesh The triangulated mesh.
    Mesh2f (*TriangulatePolygon)(const Polygon2f* polygons, uint32_t numPolygons);

    /// Free the memory allocated by TriangulatePolygon.
    ///
    /// @param[in] mesh The mesh to free.
    void (*FreeMesh)(Mesh2f* mesh);

    /// Compute the mesh segmentation for a given set of vertices, indices and points per unit.
    /// The function will automatically generate segmentation points in a uniform voxel grid
    /// within the mesh bounds. You *MUST* call FreeMeshSegmentation() on the meshSegments array when
    /// you are done with it or you will leak memory.
    ///
    /// @param[in] vertices The mesh vertices.
    /// @param[in] numVertices The number of vertices in the mesh.
    /// @param[in] indices The mesh indices.
    /// @param[in] numIndices The number of indices in the mesh.
    /// @param[in] pointsPerUnitX The number of points per unit along the X axis.
    /// @param[in] pointsPerUnitY The number of points per unit along the Y axis.
    /// @param[in] pointsPerUnitZ The number of points per unit along the Z axis.
    /// @param[in] reservedMin The minimum bounding box for the reserved segment.
    /// @param[in] reservedMax The maximum bounding box for the reserved segment.
    /// @param[out] meshSegments The resulting segments.
    /// @param[out] numSegments The number of segments in the resulting array.
    /// @param[out] reservedSegment The segment that is inside the reserved bounding box.
    Result (*ComputeMeshSegmentation)(const FVector3f* vertices, uint32_t numVertices, const uint32_t* indices, uint32_t numIndices, float pointsPerUnitX, float pointsPerUnitY, float pointsPerUnitZ, FVector3f reservedMin, FVector3f reservedMax, Mesh3f** meshSegments, uint32_t* numSegments, Mesh3f* reservedSegment);

    /// Free the memory allocated by ComputeMeshSegmentation.
    ///
    /// @param[in] meshSegments The array of segments to free.
    /// @param[in] numSegments The number of segments in the array.
    /// @param[in] reservedSegment The reserved segment to free.
    void (*FreeMeshSegmentation)(const Mesh3f* meshSegments, uint32_t numSegments, Mesh3f* reservedSegment);

    /// The is a test function purely to test the marshalling of Uuid from C# to C++. It ensures that
    /// the packing between clang C++ and the C# definitions of MrukUuid are compatible.
    ///
    /// @param[in] packedUuid A uuid packed into a structure.
    /// @return A copy of the uuid that was passed in the structure.
    Uuid (*_TestUuidMarshalling)(_MrukUuidAlignmentTest packedUuid);

    /// Converts the given label to the matching MrukLabel.
    ///
    /// @param[in] label The label as string.
    /// @return The converted MrukLabel.
    Label (*StringToMrukLabel)(const char* label);

    /// Creates the enviornment raycaster and fires the onEnvironmentRaycasterCreated event when the
    /// creation is complete.
    Result (*CreateEnvironmentRaycaster)();

    /// Destroys the enviornment raycaster.
    void (*DestroyEnvironmentRaycaster)();

    /// Check the status of the environment raycaster.
    EnvironmentRaycasterStatus (*EnvironmentRaycasterStatus)();

    /// Performs an environment raycast.
    /// Ensure that the environment raycaster is created before calling this function.
    /// @param[in] info The raycast info.
    /// @param[out] hitPoint The hit point.
    Result (*RaycastEnvironment)(const EnvironmentRaycastHitPointGetInfo* info, EnvironmentRaycastHitPoint* hitPoint);
    void (*SetTrackingSpacePoseGetter)(TrackingSpacePoseGetter getter);
    void (*SetTrackingSpacePoseSetter)(TrackingSpacePoseSetter setter);

    /// Configures the tracker services. This should only be called after the global context
    /// has been created. The trackers that should be enabled can be passed in trackableMask.
    /// 0 means all trackers will be disabled.
    /// The event onTrackersConfigured will be emitted after the tracker service is ready or failed to
    /// start.
    ///
    /// @param[in] trackableMask A bitmask of MrukTrackableType
    void (*ConfigureTrackers)(uint32_t trackableMask);

    /// Set the interval in which trackers will be queried from the system and updated.
    /// @param[in] millseconds Time in millseconds between updates
    void (*SetTrackersUpdateInterval)(uint64_t millseconds);

    /// Checks if QR code tracking is supported by the current system.
    ///
    /// @return True if QR code tracking is supported, false otherwise.
    bool (*CheckQrCodeTrackingSupported)();

    /// Gets the supported resolutions for the specified camera.
    /// This function allocates a buffer in C++ and returns a pointer to it.
    /// The caller is responsible for freeing the buffer by calling CameraFreeSupportedResolutions.
    ///
    /// @param[in] eyeIndex The index of the camera.
    /// @param[out] len Will be set to the number of available resolutions.
    /// @return A pointer to an array of MrukVector2i structures, where x is the width and y is the
    /// height. The caller must free this buffer by calling CameraFreeSupportedResolutions. Returns NULL
    /// if no resolutions are available or an error occurred.
    Vector2i* (*CameraGetSupportedResolutions)(int eyeIndex, int* len);

    /// Frees the buffer allocated by CameraGetSupportedResolutions.
    ///
    /// @param[in] buffer The buffer to free.
    void (*CameraFreeSupportedResolutions)(Vector2i* buffer);

    /// Starts the camera capture for the specified camera.
    /// @param[in] eyeIndex The index of the camera to start.
    /// @param[out] width The width of the camera frames that will be captured.
    /// @param[out] height The height of the camera frames that will be captured.
    /// @param[out] intrinsics The intrinsic parameters of the camera.
    /// @param[in] maxFramerate The maximum frames per second for the camera stream.
    /// @return True if the camera was successfully started, false otherwise.
    bool (*CameraPlay)(int eyeIndex, int* width, int* height, CameraIntrinsics* intrinsics, int maxFramerate);

    /// If CameraPlay() returns `true`, the engine should create a render texture and pass its
    /// `nativeTex` pointer to this function. Shared library will update the `nativeTex` directly when
    /// CameraUpdateNativeTexture() is called.
    ///
    /// @param[in] eyeIndex The index of the camera for which the native texture is being set.
    /// @param[in] nativeTex A pointer to the native texture created in the engine.
    void (*CameraSetNativeTexture)(int eyeIndex, void* nativeTex);

    /// Should be called on the render thread if CameraGetLatestImage() returns `true` in the current
    /// frame.
    /// @param[in] eyeIndex Index of the camera eye.
    void (*CameraUpdateNativeTexture)(int eyeIndex);

    /// Call this function on the Unity render thread of the application when it launches. It
    /// initializes the necessary GPU code to process camera images.
    ///
    /// @param[in] unused Unused parameter. Left in the signature for compatibility with Unitys calling
    /// conventions.
    void (*CameraInitializeFromUnity)(int unused);

    /// Initializes the Vulkan backend for camera image processing.
    /// This function should be called after the Vulkan instance, physical device, and logical device
    /// have been created in the engine. The shared library will use the provided Vulkan handles to
    /// manage camera image resources and perform GPU operations.
    /// This function should be called on the render thread of the application.
    ///
    /// @param[in] vulkanInstance         Handle to the Vulkan instance.
    /// @param[in] vulkanPhysicalDevice   Handle to the Vulkan physical device.
    /// @param[in] vulkanDevice           Handle to the Vulkan logical device.
    /// @param[in] graphicsQueue          Handle to the Vulkan graphics queue.
    /// @param[in] queueFamilyIndex       Index of the queue family used for graphics operations.
    /// @param[in] vulkanGetProcAddrFunc  Pointer to the vkGetInstanceProcAddr function.
    void (*CameraInitializeVulkan)(uint64_t vulkanInstance, uint64_t vulkanPhysicalDevice, uint64_t vulkanDevice, uint64_t graphicsQueue, uint32_t queueFamilyIndex, void* vulkanGetProcAddrFunc);

    /// Deinitialize the GPU code. In Unity this will be called automatically in this library.
    void (*CameraDeinitialize)();

    /// Acquires the latest image from the camera and adds it to a queue. This function should be called
    /// from the engine's main thread early in the frame. If this function returns `true`, the engine
    /// should schedule a call to CameraUpdateNativeTexture() on the render thread. In Unity,
    /// it's done with GL.IssuePluginEvent().
    /// @param[in] eyeIndex The index of the camera.
    /// @param[out] timestampMicrosecondsRealtime Timestamp of the image in microseconds since
    /// the Unix epoch.
    /// @param[out] timestampNsMonotonic Timestamp of the image in monotonic nanoseconds. Used for
    /// getting the precise headset pose at the image's timestamp.
    /// @return `true` if the image was successfully enqueued, `false` otherwise.
    bool (*CameraGetLatestImage)(int eyeIndex, int64_t* outTimestampMicrosecondsRealtime, int64_t* outTimestampNsMonotonic);

    /// Notifies the camera system that the application has gained focus.
    /// This should be called when the application regains focus after being in the background.
    void (*CameraOnApplicationFocused)();

    /// Stops the camera capture for the specified camera.
    /// @param[in] eyeIndex The index of the camera to stop.
    void (*CameraStop)(int eyeIndex);

    /// Acquires the latest image from the camera.
    /// The caller must call CameraReleaseLatestImage() afterwards, even if the returned buffer is null.
    /// @param[in] eyeIndex The index of the camera.
    /// @param[out] timestampMicrosecondsRealtime Timestamp of the image in microseconds since
    /// the Unix epoch.
    /// @param[out] timestampNsMonotonic Timestamp of the image in monotonic nanoseconds. Used for
    /// getting the precise headset pose at the image's timestamp.
    /// @return A pointer to a buffer containing the RGBA (32 bits, 8 bits per channel) image data. If
    /// null, this means no new image is available.
    uint8_t* (*CameraAcquireLatestCpuImage)(int eyeIndex, int64_t* timestampMicrosecondsRealtime, int64_t* timestampNsMonotonic);

    /// Releases the image buffer acquired by CameraAcquireLatestImage().
    /// Must be called even if CameraAcquireLatestImage() returns null.
    void (*CameraReleaseLatestCpuImage)(int eyeIndex);

    /// Converts a timestamp in nanoseconds to seconds in XR time domain.
    ///
    /// @param[in] timeNsMonotonic The timestamp in nanoseconds (monotonic clock).
    /// @return The corresponding time in seconds as a double.
    double (*ConvertToXrTimeInSeconds)(int64_t timeNsMonotonic);

    /// Get the headset's pose at the given timestamp
    /// @param[in] time The timestamp in nanoseconds
    /// @param[out] outPosition The headset position
    /// @param[out] outOrientation The headset orientation
    void (*GetHeadsetPoseAtTime)(int64_t time, FVector3f* outPosition, Quatf* outOrientation);

private:

    void LoadNativeFunctions()
    {
        SetLogPrinter = reinterpret_cast<decltype(SetLogPrinter)>(LoadFunction(TEXT("SetLogPrinter")));
        CreateGlobalContext = reinterpret_cast<decltype(CreateGlobalContext)>(LoadFunction(TEXT("CreateGlobalContext")));
        DestroyGlobalContext = reinterpret_cast<decltype(DestroyGlobalContext)>(LoadFunction(TEXT("DestroyGlobalContext")));
        InitOpenXr = reinterpret_cast<decltype(InitOpenXr)>(LoadFunction(TEXT("InitOpenXr")));
        ShutdownOpenXr = reinterpret_cast<decltype(ShutdownOpenXr)>(LoadFunction(TEXT("ShutdownOpenXr")));
        InitGraphicsFromUnity = reinterpret_cast<decltype(InitGraphicsFromUnity)>(LoadFunction(TEXT("InitGraphicsFromUnity")));
        InitGraphics = reinterpret_cast<decltype(InitGraphics)>(LoadFunction(TEXT("InitGraphics")));
        SetBaseSpace = reinterpret_cast<decltype(SetBaseSpace)>(LoadFunction(TEXT("SetBaseSpace")));
        StartDiscovery = reinterpret_cast<decltype(StartDiscovery)>(LoadFunction(TEXT("StartDiscovery")));
        StartQueryByLocalGroup = reinterpret_cast<decltype(StartQueryByLocalGroup)>(LoadFunction(TEXT("StartQueryByLocalGroup")));
        LoadSceneFromJson = reinterpret_cast<decltype(LoadSceneFromJson)>(LoadFunction(TEXT("LoadSceneFromJson")));
        SaveSceneToJson = reinterpret_cast<decltype(SaveSceneToJson)>(LoadFunction(TEXT("SaveSceneToJson")));
        FreeJson = reinterpret_cast<decltype(FreeJson)>(LoadFunction(TEXT("FreeJson")));
        LoadSceneFromPrefab = reinterpret_cast<decltype(LoadSceneFromPrefab)>(LoadFunction(TEXT("LoadSceneFromPrefab")));
        ClearRooms = reinterpret_cast<decltype(ClearRooms)>(LoadFunction(TEXT("ClearRooms")));
        ClearRoom = reinterpret_cast<decltype(ClearRoom)>(LoadFunction(TEXT("ClearRoom")));
        OnOpenXrEvent = reinterpret_cast<decltype(OnOpenXrEvent)>(LoadFunction(TEXT("OnOpenXrEvent")));
        TickGlobalContext = reinterpret_cast<decltype(TickGlobalContext)>(LoadFunction(TEXT("TickGlobalContext")));
        RegisterEventListener = reinterpret_cast<decltype(RegisterEventListener)>(LoadFunction(TEXT("RegisterEventListener")));
        RaycastRoom = reinterpret_cast<decltype(RaycastRoom)>(LoadFunction(TEXT("RaycastRoom")));
        RaycastRoomAll = reinterpret_cast<decltype(RaycastRoomAll)>(LoadFunction(TEXT("RaycastRoomAll")));
        RaycastAnchor = reinterpret_cast<decltype(RaycastAnchor)>(LoadFunction(TEXT("RaycastAnchor")));
        RaycastAnchorAll = reinterpret_cast<decltype(RaycastAnchorAll)>(LoadFunction(TEXT("RaycastAnchorAll")));
        IsPositionInRoom = reinterpret_cast<decltype(IsPositionInRoom)>(LoadFunction(TEXT("IsPositionInRoom")));
        GetCurrentRoom = reinterpret_cast<decltype(GetCurrentRoom)>(LoadFunction(TEXT("GetCurrentRoom")));
        IsDiscoveryRunning = reinterpret_cast<decltype(IsDiscoveryRunning)>(LoadFunction(TEXT("IsDiscoveryRunning")));
        SetCustomWorldLockAnchor = reinterpret_cast<decltype(SetCustomWorldLockAnchor)>(LoadFunction(TEXT("SetCustomWorldLockAnchor")));
        ErasePersistedWorldLockAnchor = reinterpret_cast<decltype(ErasePersistedWorldLockAnchor)>(LoadFunction(TEXT("ErasePersistedWorldLockAnchor")));
        GetWorldLockOffset = reinterpret_cast<decltype(GetWorldLockOffset)>(LoadFunction(TEXT("GetWorldLockOffset")));
        AddVectors = reinterpret_cast<decltype(AddVectors)>(LoadFunction(TEXT("AddVectors")));
        TriangulatePolygon = reinterpret_cast<decltype(TriangulatePolygon)>(LoadFunction(TEXT("TriangulatePolygon")));
        FreeMesh = reinterpret_cast<decltype(FreeMesh)>(LoadFunction(TEXT("FreeMesh")));
        ComputeMeshSegmentation = reinterpret_cast<decltype(ComputeMeshSegmentation)>(LoadFunction(TEXT("ComputeMeshSegmentation")));
        FreeMeshSegmentation = reinterpret_cast<decltype(FreeMeshSegmentation)>(LoadFunction(TEXT("FreeMeshSegmentation")));
        _TestUuidMarshalling = reinterpret_cast<decltype(_TestUuidMarshalling)>(LoadFunction(TEXT("_TestUuidMarshalling")));
        StringToMrukLabel = reinterpret_cast<decltype(StringToMrukLabel)>(LoadFunction(TEXT("StringToMrukLabel")));
        CreateEnvironmentRaycaster = reinterpret_cast<decltype(CreateEnvironmentRaycaster)>(LoadFunction(TEXT("CreateEnvironmentRaycaster")));
        DestroyEnvironmentRaycaster = reinterpret_cast<decltype(DestroyEnvironmentRaycaster)>(LoadFunction(TEXT("DestroyEnvironmentRaycaster")));
        EnvironmentRaycasterStatus = reinterpret_cast<decltype(EnvironmentRaycasterStatus)>(LoadFunction(TEXT("EnvironmentRaycasterStatus")));
        RaycastEnvironment = reinterpret_cast<decltype(RaycastEnvironment)>(LoadFunction(TEXT("RaycastEnvironment")));
        SetTrackingSpacePoseGetter = reinterpret_cast<decltype(SetTrackingSpacePoseGetter)>(LoadFunction(TEXT("SetTrackingSpacePoseGetter")));
        SetTrackingSpacePoseSetter = reinterpret_cast<decltype(SetTrackingSpacePoseSetter)>(LoadFunction(TEXT("SetTrackingSpacePoseSetter")));
        ConfigureTrackers = reinterpret_cast<decltype(ConfigureTrackers)>(LoadFunction(TEXT("ConfigureTrackers")));
        SetTrackersUpdateInterval = reinterpret_cast<decltype(SetTrackersUpdateInterval)>(LoadFunction(TEXT("SetTrackersUpdateInterval")));
        CheckQrCodeTrackingSupported = reinterpret_cast<decltype(CheckQrCodeTrackingSupported)>(LoadFunction(TEXT("CheckQrCodeTrackingSupported")));
        CameraGetSupportedResolutions = reinterpret_cast<decltype(CameraGetSupportedResolutions)>(LoadFunction(TEXT("CameraGetSupportedResolutions")));
        CameraFreeSupportedResolutions = reinterpret_cast<decltype(CameraFreeSupportedResolutions)>(LoadFunction(TEXT("CameraFreeSupportedResolutions")));
        CameraPlay = reinterpret_cast<decltype(CameraPlay)>(LoadFunction(TEXT("CameraPlay")));
        CameraSetNativeTexture = reinterpret_cast<decltype(CameraSetNativeTexture)>(LoadFunction(TEXT("CameraSetNativeTexture")));
        CameraUpdateNativeTexture = reinterpret_cast<decltype(CameraUpdateNativeTexture)>(LoadFunction(TEXT("CameraUpdateNativeTexture")));
        CameraInitializeFromUnity = reinterpret_cast<decltype(CameraInitializeFromUnity)>(LoadFunction(TEXT("CameraInitializeFromUnity")));
        CameraInitializeVulkan = reinterpret_cast<decltype(CameraInitializeVulkan)>(LoadFunction(TEXT("CameraInitializeVulkan")));
        CameraDeinitialize = reinterpret_cast<decltype(CameraDeinitialize)>(LoadFunction(TEXT("CameraDeinitialize")));
        CameraGetLatestImage = reinterpret_cast<decltype(CameraGetLatestImage)>(LoadFunction(TEXT("CameraGetLatestImage")));
        CameraOnApplicationFocused = reinterpret_cast<decltype(CameraOnApplicationFocused)>(LoadFunction(TEXT("CameraOnApplicationFocused")));
        CameraStop = reinterpret_cast<decltype(CameraStop)>(LoadFunction(TEXT("CameraStop")));
        CameraAcquireLatestCpuImage = reinterpret_cast<decltype(CameraAcquireLatestCpuImage)>(LoadFunction(TEXT("CameraAcquireLatestCpuImage")));
        CameraReleaseLatestCpuImage = reinterpret_cast<decltype(CameraReleaseLatestCpuImage)>(LoadFunction(TEXT("CameraReleaseLatestCpuImage")));
        ConvertToXrTimeInSeconds = reinterpret_cast<decltype(ConvertToXrTimeInSeconds)>(LoadFunction(TEXT("ConvertToXrTimeInSeconds")));
        GetHeadsetPoseAtTime = reinterpret_cast<decltype(GetHeadsetPoseAtTime)>(LoadFunction(TEXT("GetHeadsetPoseAtTime")));
    }

    void UnloadNativeFunctions()
    {
        SetLogPrinter = nullptr;
        CreateGlobalContext = nullptr;
        DestroyGlobalContext = nullptr;
        InitOpenXr = nullptr;
        ShutdownOpenXr = nullptr;
        InitGraphicsFromUnity = nullptr;
        InitGraphics = nullptr;
        SetBaseSpace = nullptr;
        StartDiscovery = nullptr;
        StartQueryByLocalGroup = nullptr;
        LoadSceneFromJson = nullptr;
        SaveSceneToJson = nullptr;
        FreeJson = nullptr;
        LoadSceneFromPrefab = nullptr;
        ClearRooms = nullptr;
        ClearRoom = nullptr;
        OnOpenXrEvent = nullptr;
        TickGlobalContext = nullptr;
        RegisterEventListener = nullptr;
        RaycastRoom = nullptr;
        RaycastRoomAll = nullptr;
        RaycastAnchor = nullptr;
        RaycastAnchorAll = nullptr;
        IsPositionInRoom = nullptr;
        GetCurrentRoom = nullptr;
        IsDiscoveryRunning = nullptr;
        SetCustomWorldLockAnchor = nullptr;
        ErasePersistedWorldLockAnchor = nullptr;
        GetWorldLockOffset = nullptr;
        AddVectors = nullptr;
        TriangulatePolygon = nullptr;
        FreeMesh = nullptr;
        ComputeMeshSegmentation = nullptr;
        FreeMeshSegmentation = nullptr;
        _TestUuidMarshalling = nullptr;
        StringToMrukLabel = nullptr;
        CreateEnvironmentRaycaster = nullptr;
        DestroyEnvironmentRaycaster = nullptr;
        EnvironmentRaycasterStatus = nullptr;
        RaycastEnvironment = nullptr;
        SetTrackingSpacePoseGetter = nullptr;
        SetTrackingSpacePoseSetter = nullptr;
        ConfigureTrackers = nullptr;
        SetTrackersUpdateInterval = nullptr;
        CheckQrCodeTrackingSupported = nullptr;
        CameraGetSupportedResolutions = nullptr;
        CameraFreeSupportedResolutions = nullptr;
        CameraPlay = nullptr;
        CameraSetNativeTexture = nullptr;
        CameraUpdateNativeTexture = nullptr;
        CameraInitializeFromUnity = nullptr;
        CameraInitializeVulkan = nullptr;
        CameraDeinitialize = nullptr;
        CameraGetLatestImage = nullptr;
        CameraOnApplicationFocused = nullptr;
        CameraStop = nullptr;
        CameraAcquireLatestCpuImage = nullptr;
        CameraReleaseLatestCpuImage = nullptr;
        ConvertToXrTimeInSeconds = nullptr;
        GetHeadsetPoseAtTime = nullptr;
    }

    void* LoadFunction(const TCHAR* ProcName);

    static MRUKShared* Instance;
    void* MRUKSharedHandle;

    MRUKShared(void* handle);
    ~MRUKShared();
};
